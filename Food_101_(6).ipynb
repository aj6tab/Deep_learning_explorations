{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Food-101 (6).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aj6tab/Deep_learning_explorations/blob/master/Food_101_(6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLQdMhzZN7FK",
        "colab_type": "text"
      },
      "source": [
        "# Food-101 \n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "### Problem Statement\n",
        "<p>\n",
        "We introduce a challenging data set of 101 food categories, with 101'000 images. For each class, 250 manually reviewed test images are provided as well as 750 training images. On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. All images were rescaled to have a maximum side length of 512 pixels.\n",
        "</p>\n",
        "\n",
        "### Dataset\n",
        "\n",
        "[Training and Test dataset](http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz) for the challenge. \n",
        "<br>\n",
        "\n",
        "### Evaluation Metric\n",
        " \n",
        "*** Accuracy ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "id-svi96N7FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ../input/food-101/food-101/\n",
        "!ls food-101/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKBJRd_6N7FQ",
        "colab_type": "text"
      },
      "source": [
        "**meta** folder contains the text files - train.txt and test.txt <br>\n",
        "**train.txt** contains the list of images that belong to training set <br>\n",
        "**test.txt** contains the list of images that belong to test set <br>\n",
        "**classes.txt** contains the list of all classes of food <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLgDIzpDN7FQ",
        "colab_type": "text"
      },
      "source": [
        "**images** folder contains 101 folders with 1000 images each. <br>\n",
        "Following Classes of Food items available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "f6R42q3SN7FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls food-101/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMr5hQAcN7FW",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "x9S01vpBN7FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from shutil import copy\n",
        "import os\n",
        "import gc\n",
        "\n",
        "# Helper method to split dataset into train and test folders\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LOuITldsN7Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('/kaggle/input/food-101/food-101/food-101/meta/train.txt', '/kaggle/input/food-101/food-101/food-101/images', 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aenwfhPYN7Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('/kaggle/input/food-101/food-101/food-101/meta/test.txt', '/kaggle/input/food-101/food-101/food-101/images', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fUvUWW8uN7Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Total number of samples in train folder\")\n",
        "!find train -type d -or -type f -printf '.' | wc -c\n",
        "\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp0ky6SoN7Fl",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FOVUjCqEN7Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.metrics import accuracy\n",
        "from fastai.vision import *\n",
        "\n",
        "BS = 16\n",
        "SEED = 786\n",
        "NUM_WORKERS = 6\n",
        "\n",
        "from pathlib import Path\n",
        "path = Path('/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4mDzv-P1N7Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "tfms = get_transforms(flip_vert=False, max_lighting=0.1, max_zoom=1.05, max_warp=0., xtra_tfms=[cutout()])\n",
        "\n",
        "src = (ImageList.from_folder(path/'train')\n",
        "       .split_by_rand_pct(0.2)\n",
        "       .label_from_folder())\n",
        "\n",
        "data = (src.add_test_folder(test_folder = path/'test')              \n",
        "         .transform(tfms, size=128)\n",
        "         .databunch(num_workers=NUM_WORKERS,bs=BS)).normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLjr2Hu1N7Ft",
        "colab_type": "text"
      },
      "source": [
        "**Creating data bunch with size 128 x 128**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tYHHzEUjN7Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.show_batch(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Szz2S2VAN7Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "learner = cnn_learner(\n",
        "    data,\n",
        "    models.resnet50,\n",
        "    path=path,\n",
        "    metrics=[accuracy],\n",
        "    ps = 0.5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R6GocdlmN7F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9dtFjB8IN7F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-02\n",
        "learner.fit_one_cycle(1, slice(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CjVvxJxkN7GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('FOOD101_stage-1')\n",
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OwTNHZprN7GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(2, slice(1e-6, lr/5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-TiHxk_mN7GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('FOOD101_stage-2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyWEsBNVN7GL",
        "colab_type": "text"
      },
      "source": [
        "**Creating data bunch with size 256 x 256. Feeding the data to the same model we have trained on 128 x 128 images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OEtd5hjfN7GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (src.add_test_folder(test_folder = path/'test')              \n",
        "         .transform(tfms, size=256)\n",
        "         .databunch(num_workers=NUM_WORKERS,bs=BS)).normalize(imagenet_stats)\n",
        "\n",
        "learner.data = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CFwiDuPsN7GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nd16fLckN7GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=1e-2\n",
        "learner.fit_one_cycle(1, slice(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcq0gKVxN7GV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LZcIwCS4N7GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('FOOD101_stage-1-256')\n",
        "learner.unfreeze()\n",
        "learner.fit_one_cycle(2, slice(1e-6, 1e-5\n",
        "                               /5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RNnLfHUMN7Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.recorder.plot_losses()\n",
        "learner.save('FOOD101_stage-2-256')\n",
        "learner.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECZYSuRwN7Gf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Creating data bunch with size 512 x 512 (Original Image Size). Feeding the data to the same model we have trained on 128 x 128 & 256 x 256 images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "llPtCQslN7Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (src.add_test_folder(test_folder = path/'test')              \n",
        "         .transform(tfms, size=512)\n",
        "         .databunch(num_workers=NUM_WORKERS,bs=BS)).normalize(imagenet_stats)\n",
        "\n",
        "learner.data = data\n",
        "\n",
        "learner.freeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4kqbMGYKN7Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=1e-5/2\n",
        "learner.fit_one_cycle(1, slice(lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fuF4GbyqN7Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('FOOD101_stage-1-512')\n",
        "learner.unfreeze()\n",
        "learner.fit_one_cycle(2, slice(1e-6, 1e-5/2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-39cvZINN7Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.recorder.plot_losses()\n",
        "learner.save('FOOD101_stage-2-512')\n",
        "learner.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jolv6VGN7Gx",
        "colab_type": "text"
      },
      "source": [
        "**Test Data Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BbVJeHjdN7Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "src = (ImageDataBunch.from_folder(path = path, train = 'train', valid = 'test')\n",
        "       .split_by_rand_pct(0.2)\n",
        "       .label_from_folder())\n",
        "\n",
        "data = (src.transform(tfms, size=512)\n",
        "         .databunch(num_workers=NUM_WORKERS,bs=BS)).normalize(imagenet_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FeAwoCd1N7G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_one_cycle(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "m_hezzbzN7G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_class(model, images, show = True):\n",
        "    for img in images:\n",
        "        im = open_image(img)\n",
        "        pred,_,_ = model.predict(im)\n",
        "        if show:\n",
        "            plt.imshow(image2np(im.data))                      \n",
        "            plt.axis('off')\n",
        "            print(pred)\n",
        "            plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_1A_766QN7G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# list all files in dir\n",
        "files = [y for x in os.listdir(\"/test/\") for y in os.listdir(os.path.join(\"/test/\", x)) if os.path.isfile(y)]\n",
        "\n",
        "# select 0.1 of the files randomly \n",
        "random_files = np.random.choice(files, int(len(files)*.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SqVXL-TN7G_",
        "colab_type": "text"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0KYiGaOgN7HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_class(learner, random_files,True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SxgJo-IQN7HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install jovian --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yQj8As_9N7HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T2mUvEONN7HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jovian.commit(project='Food101_Project')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c2-T5sLaN7HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}